{"/about/community/":{"data":{"":"","comminity#Comminity":"","github#GitHub":"Project on GitHub Contribute Report SG-Runner or SG-Commander issuues Contribute to docs","mission#Mission":"To enable efficient and reliable telecom signaling simulation by developing high-quality, scalable, and open-source signaling generators that support testing, validation, and innovation across modern networks.","slack#Slack":"Got questions? We have a thriving community to help you.\nSea slack channel Our team and community members are reachable over chat channel GitHub Scenarion Support You can report them directly on our GitHub Issues page at Atos Soft Sea GitHub Issues. Our team and community members monitor these issues regularly and strive to provide timely responses. Stack Overflow community-driven question and answer platform and we actively participate in discussions.","vision#Vision":"To become the leading open-source platform for telecom signaling simulation, empowering organizations and communities worldwide to build, test, and innovate with confidence."},"title":"community"},"/about/contact/":{"data":{"":"","channels#Channels":"Sea slack channel Our team and community members are reachable over chat channel GMS Teams Our team strive to provide timely responses.","contacts#Contacts":"","emails#Emails":"Support: support(at)atosandsea.io Common: contact(at)atosandsea.io"},"title":"contact"},"/about/support/":{"data":{"":"","feadback#Feadback":"We welcome your feedback and suggestions!\nPlease reach out to us at contact (at) atosandsea.io — your input helps us improve and better serve the telecom signaling simulation community","support#Support":"Beyond community support, we offer premium services designed specifically for MNOs and MVNOs operating in demanding, large-scale test environments.\nFrom tailored feature development and protocol enhancements to seamless integration and expert consulting, we help organizations accelerate deployment, optimize performance, and confidently scale their telecom signaling simulations.\nGot questions? We have a thriving community to help you.\nSea slack channel Our team and community members are reachable over chat channel GitHub Scenarion Support You can report them directly on our GitHub Issues page at Atos Soft Sea GitHub Issues. Our team and community members monitor these issues regularly and strive to provide timely responses. Expert telecom signaling support — faster, scalable, reliable. Let ATOS \u0026\u0026 SEA help you optimize your test scenarios. Email contact (at) atosandsea.io today."},"title":"support"},"/about/usecases/":{"data":{"":"","spike-traffic-blend-of-data-voice-sms-and-provsioning#Spike traffic, blend of data, voice, sms and provsioning":"Project Request\nPerfromance test of OCS system suprting Gy,Sy and RestApi interface, having set of data , voice, sms and provsiong scenarios.\nset of scenarios manage average traffic handle spikes, stress system pushing beyond its limits Strategy\ndiameter scenarios of data, voice and sms applying Gy and Sy traffic restApi scenarios for blend of provsionign traffic generate test data applied to different scenarios and subscribers profiles manage last run test manage spiek test Test Runer setup\ncloud enviroment with reasanble high capacity seagull tool for diameter jmeter tool test data generting by dsl perl tool reprting ansible for montoring of sytem under test, symtoms collection managed","spike-traffic-blend-of-data-voice-sms-and-provsioning-1#Spike traffic, blend of data, voice, sms and provsioning":"Project Request\nPerfromance test of OCS system suprting Gy,Sy and RestApi interface, having set of data , voice, sms and provsiong scenarios.\nset of scenarios manage average traffic handle spikes, stress system pushing beyond its limits Strategy\ndiameter scenarios of data, voice and sms applying Gy and Sy traffic restApi scenarios for blend of provsionign traffic generate test data applied to different scenarios and subscribers profiles manage last run test manage spiek test Test Runer setup\ncloud enviroment with reasanble high capacity seagull tool for diameter jmeter tool test data generting by dsl perl tool reprting ansible for montoring of sytem under test, symtoms collection managed","use-cases#Use Cases":""},"title":"usecases"},"/blog/blog_1/":{"data":{"":"Project Request\nPerfromance test of OCS system suprting Gy,Sy and RestApi interface, having set of data , voice, sms and provsiong scenarios.\nset of scenarios manage average traffic handle spikes, stress system pushing beyond its limits Strategy\ndiameter scenarios of data, voice and sms applying Gy and Sy traffic restApi scenarios for blend of provsionign traffic generate test data applied to different scenarios and subscribers profiles manage last run test manage spiek test Test Runer setup\ncloud enviroment with reasanble high capacity seagull tool for diameter jmeter tool test data generting by dsl perl tool reprting ansible for montoring of sytem under test, symtoms collection managed"},"title":"Spike traffic, blend of data, voice, sms and provsioning"},"/docs/":{"data":{"":"The Atos\u0026\u0026Sea is market name for an open-source telco proejct, focused on Collaborative Telecommunication Testing Paltform.\nThe project aligns with Zero-Touch Telecommunication initiatives\nTelecommunication testing is complex and fragmented across multiple protocols, makes collaboration and reproducibility difficult.\nCurrent solutions are proprietary, limiting flexibility and sharing. The Signaling-Gateway platform breaks down the barriers posed by complex Telco protocols while integrating existing tools.\nThe SG platfrom defines, executes,observs and share test scenarios for Nordbound or Southbound traffic, supporting collaborative test development and following 3GPP standardization.\nThe varety of tools are integrated and managed by an orchestrator, providing a central location for configuration and templating. Telecom engineers, QA teams, open-source enthusiasts, and researchers in telco network testing","benifits#Benifits":"Unifies multiple tools into a single platform for easier performance and end-to-end testing Flexible testing, independent of proprietary tools or vendors Handles complex 4G/5G Telco protocols and enables scenario sharing Dynamically scales resources to maximize efficiency and minimize cost","key-features#Key Features":"Support for multiple protocols - DIAMETER, SIP, 5G core HTTP RestApi, SOAP, XML, REST and HTTP Flexible test scenario configuration Graphical, statistical, and summary reports Collaborative sharing of test scneario and exchange results and expirances Open-source and extensible based on Python, Docker, K8S, Jmeter and Seagull Simplifies performance testing by managing multiple blended scenarios Optimize performance testing by scaling resources as needed"},"title":"Documentations"},"/docs/guide/":{"data":{"":"The SG platformThe SG platform is built around two core components that together streamline Telco performance testing:\nSG-Runner: Executes tests and simulates complex Telco protocols, providing accurate and reliable performance insights. SG-Commander: Orchestrates multiple test scenarios, manages resources efficiently, and ensures scalable, coordinated test execution across the platform."},"title":"Introductions"},"/docs/guide/sg-test-store/":{"data":{"":"The Test Store is more than a platform – it’s a hub for ideas, experiences, and knowledge-sharing across the telecom community. Here, engineers focus on what truly matters: smart test strategies and thoughtful test design, not just the tools.\nWhy repeat what’s already been done? Many tests are similar across vendors and operators. Instead, the Test Store helps the community share best practices, spark innovation, and accelerate progress in the telecom world. Together, we can push the boundaries of what’s possible and shape the future of telecom.","test-smarter-share-faster-transform-telecom#Test Smarter. Share Faster. Transform Telecom.":"Join the Test Store – a community where telecom engineers focus on strategy, design, and innovation. Share ideas, learn from others, and help shape the future of telecom. Our tests support 5G, 4G, Diameter, SIP, HTTP and provisioning interfaces, so you can work with real-world technologies without reinventing the wheel. Together, we move the industry forward."},"title":"SG-TEST-STORE"},"/docs/guide/sg-test-store/core_concepts/":{"data":{"":"Directory Structure\nenv Dev sea_pgw.yml sea_ims.yml sea_smsc.yml sea_mme.yml Lab01 Lab02 tests data profile_A.csv profile_B.csv profile_C.csv SEA-OCS-01 test.yml SEA-MME-01 test.yml SER-OCS-00 test.yml SER-HSS-00 test.yml scens dico dico_base_once.xml dico_GySyCx.xml dico_GySyS6.xml sg_data scen.yml sea_scen_gysy2c_slr_ccrIU_snr_ccrUT_str.j2 sg_conf_c2ip.j2 sg_ims_sms scen.yml sea_scen_gy1c_ims_sms.j2 sg_conf_c1ip_ADJ.j2 sg_ims_voice scen.yml sea_scen_gy1c_ims_voice.j2 sg_conf_c2ip.j2 sg_mme scen.yml sea_scen_s6as6d1c_auth.j2 sg_conf_c1ip.j2 sg_5g_http scen.yml"},"title":"Core Concepts"},"/docs/guide/sg-test-store/e2e/":{"data":{"":"An end-to-end test strategy outlines the approach used to validate complete business workflows across the entire application ecosystem. It ensures that all integrated components—UI, APIs, databases, and external services—work together as expected in real-world scenarios.\nThe strategy focuses on critical user journeys that have the highest business impact. Testing is performed in a production-like environment using stable test data to closely simulate actual usage. Only essential workflows are covered to avoid redundancy, following the test pyramid principle. A combination of manual and automated testing is used.\nManual testing supports exploratory and newly developed features, while automation is applied to stable, high-value regression flows.\nTest execution is aligned with release cycles and CI/CD pipelines to provide timely feedback.\nClear pass/fail criteria, defect tracking, and reporting mechanisms are defined to ensure quick identification of issues.\nRegular maintenance of test cases and automation scripts is performed to keep the E2E test suite reliable, efficient, and scalable."},"title":"End-to-End"},"/docs/guide/sg-test-store/overview/":{"data":{"":"","features#Features":"Test Environment Driven: Each test is executed within a specific environment. Environment Configuration: Every environment includes configurations for the relevant network nodes. Test Composition: A test consists of multiple test scenarios. Scenario Parameters: Each scenario can have its own specific parameters. Scenario Focus: The scenario is primarily focused on tool configuration. Template-Based Execution: Scenarios use Jinja2 template files that are specific to the testing tool. Default Parameters: Scenarios include default parameters that are generally applicable. Template Engine: All tool templates are built on the Jinja2 engine, enabling flexible and dynamic configuration."},"title":"Overview"},"/docs/guide/sg-test-store/perf/":{"data":{"":"Last test: long runnung Test Spikes test: high traffic in short period of time Stress test: high traffic until system chrash, finds breaking point and failure behavior Volume test: high loaded data Scalability Testing check proper adding resources","test-strategy#Test Strategy":"Define test scenarios that are most important Define test data blends Define test scenarios belnd accoding to traffics needs Define Test exit criteria in term response time, failed rate, and utilisation of system under test Collect all necesselry information in advance Test model: calculat all necessary values Traffic Model file Please have a look at draft Test Strategy Document","why-performance-testing-matters#Why Performance Testing Matters":"Prevents slow apps and crashes Ensures good user experience Avoids revenue loss during peak usage Builds confidence before release Test Type Load Pattern Duration Goal Load Test Gradual Short Validate expected load Stress Test Increasing Short Find breaking point Spike Test Sudden Short Shock \u0026 recovery Endurance Test Steady Long Stability over time"},"title":"Perfromance Test"},"/docs/guide/sg-test-store/perf/last/":{"data":{"":"Last or Endurance testing checks how a system behaves when it runs under normal or moderate load for a long period of time. The focus is time, not traffic spikes.\nEndurance testing validates the stability and performance of an application under sustained load over an extended period to detect memory leaks and resource exhaustion.","application-layer#Application Layer":"Memory usage growth Thread leaks Garbage collection behavior Session handling","database-layer#Database Layer":"Open connections Lock contention Query performance degradation Cache effectiveness over time","infrastructure-layer#Infrastructure Layer":"CPU stability Disk I/O saturation Log rotation Container/VM stability","what-endurance-testing-validates#What Endurance Testing Validates":"","why-endurance-testing-is-important#Why Endurance Testing Is Important":"Some problems don’t show up immediately:\nMemory leaks Resource exhaustion Database connection leaks Log file growth Performance degradation over time Endurance testing finds these slow-burning issues."},"title":"Last Test"},"/docs/guide/sg-test-store/perf/spikes/":{"data":{"":"Spike testing validates how an application behaves and recovers when subjected to sudden, extreme changes in load.\nSpike testing validates system resilience when traffic changes instantaneously, not gradually. The goal is not to see how much load the system can take long-term, but\nHow it absorbs shock How it fails (if it does) How fast it recovers","application-layer#Application Layer:":"Thread management Request queuing Garbage collection behavior Dimeter, SIP, HTTP-2 messages or API timeouts Retry logic","data-layer#Data Layer":"Connection pool limits Lock contention Cache eviction storms Read/write latency spikes","infrastructure-layer#Infrastructure Layer":"Auto-scaling trigger thresholds Load balancer behavior Container startup times VM provisioning delay","what-spike-testing-actually-validates#What Spike Testing Actually Validates":"","when-spike-testing-is-critical#When Spike Testing Is Critical":"Spike testing is essential when:\nTraffic is event-driven User behavior is unpredictable Business impact of downtime is high","why-spike-testing#Why Spike Testing":"Spike Testing Chaos Engineering Predictable load spikes Random failures Focus on traffic Focus on fault tolerance Pre-release Often in production"},"title":"Spikes Test"},"/docs/guide/sg-test-store/perf/stress/":{"data":{"":"Stress testing evaluates how a system behaves when it is pushed beyond its normal and peak capacity until it fails.\nThe goal is not performance, it’s:\nFinding the breaking point Understanding failure behavior Checking graceful degradation \u0026 recovery","application-layer#Application Layer":"Exception handling Timeouts \u0026 retries Thread starvation Error messages shown to users","data-layer#Data Layer":"DB max connections Lock contention Slow query behavior","how-stress-testing-works#How Stress Testing Works":"Load Pattern:\nStart with normal load Gradually increase users/transactions Continue increasing until failure Observe behavior at and after failure Unlike spike tests:\nStress tests are gradual Failure is expected","infrastructure-layer#Infrastructure Layer":"CPU / memory limits Auto-scaling limits Load balancer saturation","what-stress-testing-validates#What Stress Testing Validates":""},"title":"Stress Test"},"/docs/guide/sg-test-store/supported_tests/":{"data":{"":"","diameter-client#Diameter Client":"Simulates PGW, PCRF, and MME nodes.\nTest Description SEA-OCS-01 OCS scenario combining data, voice, and SMS services, designed to simulate client PGW and PCRF SEA-HSS-01 HSS scenario supporting authorization, update, and cancellation operations. Scenario Description sg_data Supports a single rating group and the following messages: Gy/Sy CCR/CCA, SLR/SNR/STR, RAR/RAA, and DWR/DWA. sg_ims_voice Handles Gy/Sy interfaces for a single rating group, supporting PS/IMS-related AVPs and CCR/CCA, SLR/SNR/STR, RAR/RAA, and DWR/DWA sg_ims_sms Supports Gy/Sy for one rating group with PS/IMS AVPs and CCR/CCA, RAR/RAA, DWR/DWA messages. sg_mme Supports HSS avp, AAR/AAA, LUR/LUA, CLR/CLA and DWR/DWA messages sg_5g_http Supports CHF function N40/N28 interface similar as Gy/Sy scenarios","dummy-server#Dummy server":"No setup is required — the test is designed specifically for development purposes. Currently, it supports a single scenario.\nTest Description SER-OCS-00 OCS server scenario supports Gy/Sy CCR/CCA, SLR/SNR/STR ,RAR/RAA (optinally) and DWR/DWA messages SER-HSS-00 HSS server scenario supporting AAR/AAA, LUR/LUA, CLR/CLA and DWR/DWA Recommended for test devlopers\nServer are listening on localhost:3068 port."},"title":"Tests \u0026\u0026 Scenarios"},"/docs/guide/sg-test-store/test_startegy/":{"data":{"":"","end-to-end-test-strategy#End-to-End Test Strategy":"Focus on business-critical journeys Test real integrations, not mocks Keep E2E tests few but powerful Automate where stable, manual where risky Run in production-like environments","perormance-test-strategy#Perormance Test Strategy":"Define test scenarios that are most important Define test data blends Define test scenarios belnd accoding to traffics needs Define Test exit criteria in term response time, failed rate, and utilisation of system under test Collect all necesselry information in advance Test model: calculat all necessary values Traffic Model file Please have a look at draft Test Strategy Document"},"title":"Tests Strategy"},"/docs/guide/sg_commander/core_concepts/":{"data":{"":"","architecture#Architecture":"","functinalty#Functinalty":"user managment: CRUD object project managment: CRUD object order managment: CRUD object considering project and user rights, syntaax check scheduler: shedule test factory job , triggers system unter test preparation task, setup task commands controller: manage main activities , manage connectivity to the runer, manage tasks, observ test execution, collect test results","modules#Modules":"Common: manages logging, configuration, and documents db useful link Datax: main common data model objects, provides schemas and basic functinalties useful link Api: provides RestApi router and handler as well html rendering useful link Commander: provides CLI and help useful link"},"title":"Core Concepts"},"/docs/guide/sg_commander/getting_started/":{"data":{"":"","installtion#Installtion":"Metal Bear VM Docker Kubernates git clone ./sw/install.sh ./sw/test.sh import ova inot virtual box cd git clone sg-store-test docker login docker pull sg-runner:0.1.0 docker image sg-runner:0.1.0 docker image sg-runner:0.1.0 --volume store: git clone ... k8s terafform \u003c\u003e.tf kubectl cluster init ... helm update /","integration#Integration":""},"title":"Getting Started"},"/docs/guide/sg_commander/overview/":{"data":{"":"","features#Features":"The main for controlling test excutions , setup test factory and trigger pre-conditinal process. The Prof of concept is showing more detiles. Core Concept\nManagment\nuser managment project managment order managment Scheduler\ndynamic IaC managment resource avaiabilites k8s resource IaC deployment k8s/Node resorce IaC un-deplymnet k8s/node trigger SuT pre-condition process time schedulling of pre-prodition processing and test factory setup setup tasks Test Controller\nrun test , setup, pre-proc and start, status and stop run SuT monitoring run SuT pre/post-processing Hause keeping\ncollect reports from all node or containers combine report !! archive reports , pcap and logs Monitiring\nCollect monitoring results Calculate statistics Graphical and eventDb integration API\nAPi inteface VueJS application"},"title":"Overview"},"/docs/guide/sg_commander/roadmap/":{"data":{"":"","community#Community":"","sg-commander-realse-note#SG Commander: Realse Note":"Features 0.1.0 Users x Projects x Users x Orders x Scheduler x Farms x Controller Shell x Controller x Observe x Api x VueJs x Docs x"},"title":"Roadmap"},"/docs/guide/sg_runner/":{"data":{"":"","benifits#Benifits":"Large-scale / distributed perfromance or end-to-end testing Telco workloads (5G core, IMS, network functions, signaling, etc.) Cloud-native / Kubernetes orchestration (if applicable) CI/CD automates Telco QA processes Vendor- and tool-agnostic, avoiding any tool lock-in An encapsulated solution supporting a variety of tools A flexible test configuration Generate test results as graphical, statistical, and summary reports at once Collaborative sahred scnearios within the telecommunications domain Exposes a RESTful API and web GUI"},"title":"SG-RUNNER"},"/docs/guide/sg_runner/api/":{"data":{"":"","coming-soon#Coming soon":""},"title":"API References"},"/docs/guide/sg_runner/cli/":{"data":{"":"Features\nReports health, readiness, and business status Controls execution throughout all phases: setup, pre-processing, start, status monitoring, stop, and post-processing","bussiness#Bussiness":"./sbin/business.sh\nIndicates whether any tests are still running.\n[root@SEA_01 sg-runner]# ./sbin/readiness.sh\rINFO: Checking disk space of file_system=/opt/sea/sg-runner/shared and threshold is 97%.\rDEBUG: Current disk space usage is 82% for file_system=/opt/sea/sg-runner/shared\rINFO: sg-runner disk space is sufficient.\rINFO: Readiness check - - disk space use return code: 0 for /opt/sea/sg-runner/shared is below 97%\rINFO: Checking disk space available in Kb of files_system=/opt/sea/sg-runner/shared of sg-runner...\rDEBUG: Current disk space available is 3307872 Kb for files_system=/opt/sea/sg-runner/shared\rINFO: sg-runner disk space is sufficient.\rINFO: Readiness check - disk space available return code: 0 should be more than 10240 Kb\rINFO: Checking is not process_name=seagull of sg-runner running...\rINFO: sg-runner process seagull is not running.\rINFO: Readiness check - is_not_process seagull return code: 0\rINFO: Checking is not process_name=mixer.pl of sg-runner running...\rINFO: sg-runner process mixer.pl is not running.\rINFO: Readiness check - is_not_process mixer.pl return code: 0\rINFO: Checking is not process_name=gplot of sg-runner running...\rINFO: sg-runner process gplot is not running.\rINFO: Readiness check - is_not_process gplot return code: 0\rINFO: READINESS CHECK PASSED - sg-runner processes are running\r[root@SEA_01 sg-runner]# ./sbin/business.sh INFO: Checking is process_name=seagull of sg-runner running ...\rERROR: sg-runner process seagull is not running.\rINFO: Busniness check - is_process seagull return code: 1\rINFO: Checking is process_name=mixer.pl of sg-runner running ...\rERROR: sg-runner process mixer.pl is not running.\rINFO: Busniness check - is_process mixer.pl return code: 1\rINFO: Checking is process_name=gplot of sg-runner running ...\rERROR: sg-runner process gplot is not running.\rINFO: Busniness check - is_process gplot return code: 1\rINFO: BUSINESS CHECK PASSED - sg-runner processes are running\r[root@SEA_01 sg-runner]#","healty#Healty":"The health procedure consists of tools that give a clear assessment of the system’s capability to execute scenarios.","liveness#Liveness":"./sbin/liveness.sh -a -u The liveness test indicates whether the system has all the necessary tools properly set up.\nUsage: liveness.sh -a -u [root@SEA_01 sg-runner]# ./sbin/liveness.sh INFO: Checking disk space of file_system=/opt/sea/sg-runner/shared and threshold is 95%. DEBUG: Current disk space usage is 82% for file_system=/opt/sea/sg-runner/shared INFO: sg-runner disk space is sufficient. INFO: Liveness check ret_ds_use=0 - disk space use for /opt/sea/sg-runner/shared is below 95% INFO: Checking disk space available in Kb of files_system=/opt/sea/sg-runner/shared of sg-runner... DEBUG: Current disk space available is 3316752 Kb for files_system=/opt/sea/sg-runner/shared INFO: sg-runner disk space is sufficient. INFO: Liveness check - disk space available return code: 0 should be more than 10240 Kb INFO: Checking tool cmd=seagull -help exitCode=0 of sg-runner... ... DEBUG: Tool command ec=0 response: INFO: sg-runner tool seagull -help is working as expected. INFO: Liveness check - sg-runner tool return code: 0 INFO: Checking tool cmd=yq --version exitCode=0 of sg-runner... DEBUG: Tool command ec=0 response: yq 3.1.0 INFO: sg-runner tool yq --version is working as expected. INFO: Liveness check - yq tool return code: 0 INFO: Checking tool cmd=realpath --version exitCode=0 of sg-runner... DEBUG: Tool command ec=0 response: realpath (GNU coreutils) 8.30 Copyright (C) 2018 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later . This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Written by Padraig Brady. INFO: sg-runner tool realpath --version is working as expected. INFO: Liveness check - realpath tool return code: 0 INFO: Checking tool cmd=readlink --version exitCode=0 of sg-runner... DEBUG: Tool command ec=0 response: readlink (GNU coreutils) 8.30 Copyright (C) 2018 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later . This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Written by Dmitry V. Levin. INFO: sg-runner tool readlink --version is working as expected. INFO: Liveness check - readlink tool return code: 0 INFO: LIVENESS CHECK PASSED - sg-runner is healthy [root@SEA_01 sg-runner]#","post-processing#Post-Processing":"post_proc.sh","pre-processing#Pre-Processing":"pre_proc.sh","procedures#Procedures":"More details are available at Procedures","readiness#Readiness":"./sbin/readyness.sh\nIt indicates whether SG-Runner is ready for a new test execution, whether there is sufficient space, and if any tests are currently running.\n[root@SEA_01 sg-runner]# ./sbin/readiness.sh\rINFO: Checking disk space of file_system=/opt/sea/sg-runner/shared and threshold is 97%.\rDEBUG: Current disk space usage is 82% for file_system=/opt/sea/sg-runner/shared\rINFO: sg-runner disk space is sufficient.\rINFO: Readiness check - - disk space use return code: 0 for /opt/sea/sg-runner/shared is below 97%\rINFO: Checking disk space available in Kb of files_system=/opt/sea/sg-runner/shared of sg-runner...\rDEBUG: Current disk space available is 3307872 Kb for files_system=/opt/sea/sg-runner/shared\rINFO: sg-runner disk space is sufficient.\rINFO: Readiness check - disk space available return code: 0 should be more than 10240 Kb\rINFO: Checking is not process_name=seagull of sg-runner running...\rINFO: sg-runner process seagull is not running.\rINFO: Readiness check - is_not_process seagull return code: 0\rINFO: Checking is not process_name=mixer.pl of sg-runner running...\rINFO: sg-runner process mixer.pl is not running.\rINFO: Readiness check - is_not_process mixer.pl return code: 0\rINFO: Checking is not process_name=gplot of sg-runner running...\rINFO: sg-runner process gplot is not running.\rINFO: Readiness check - is_not_process gplot return code: 0\rINFO: READINESS CHECK PASSED - sg-runner processes are running\r[root@SEA_01 sg-runner]#","setup#Setup":"./sbin/setup.sh\nINFO: Test -setup started /opt/sea/sg-runner ----------------------------------------------------------------- Usage: setup.sh [-e ENV] -t TESTNAME -s SCENARIO [-d] [-p] [-b] [-v] [-h] -h show this help message and exit -e test enviroment -t test name -s scenario name -b backup test directory -d debug test tool -p packet capturing -v increase the verbosity of the bash script","start#Start":"start.sh","status#Status":"status.sh","stop#Stop":"stop.sh"},"title":"CLI"},"/docs/guide/sg_runner/configuration/":{"data":{"":"","environment-definition#Environment definition":"Main enviroment file: ./env//.yml Parameter Description env_name Environment used for the setup. ScenEnv File containing the main environment configuration for a specific scenario envName Same as the file name, without the extension envDesc Description of the environment node envSeagull Seagull configuration details (see below) envJmeter JMeter configuration details (see below)","jmeter-scenario-defination#JMeter scenario defination":"","perfromance-test-model#Perfromance test model":"Test model: for perfromance test are given at Traffic Model file","perfromance-test-model-1#Perfromance test model":"Test model: is very similar as seagull test model","scnearios-configuraion#Scnearios configuraion":"Scneario file: ./scens//scen.yml Parameter Description scenName Main scenarion name scenDesc Human-readable test description. scenTemplates The seagull conf, scenario or report jinjaj templates Channels Attributes applied to the Gy/Sy connection. Required for new environments: IP, Port, Realm/Host reportSetup report generation settings dataAttr header number is line above data are valid, report template responseTimeRepartition Time intervals used to group and measure response times. logLevel Logging level: A (All), W (Warnings), U (User), E (Errors), T (Traffic events) backgroundExec Enables execution in the background. tcpdump Network capture configuration (interface and filter using tcpdump syntax). pcapEnabled Enables or disables packet capture globally. defaultBehaviour Deafult seagull beahaviour callTimeoutMs Call time out between messages drive TPS callTimeoutAbortBehaviour In case of tameout, no expected message recesived beahvaiour msgCheckBehaviour message check beahaviour","scnearios-configuraion-1#Scnearios configuraion":"Scneario file: ./scens//scen.yml Parameter Description scenName Main scenarion name scenDesc Human-readable test description. scenTemplates The jmeter prop, scenario or report jinjaj templates reportSetup report generation settings dataAttr header number is line above data are valid, report template logLevel Logging level: backgroundExec Enables execution in the background. tcpdump Network capture configuration (interface and filter using tcpdump syntax). pcapEnabled Enables or disables packet capture globally. threadGroupTrNumber1 Thread Group-1 thread’s number threadGroupRampUp1 Thread Group-1 ramp up threadGroupLoop1 Thread Group-1 loop counter reqTimeoutMs Request time out reqSleep1Ms Sleeping msec. This is a general configuration, but it depends on the scenario itself.","seagull-scenario-defination#Seagull scenario defination":"","sg-runner#SG-Runner:":"Directory definition\nRoot directory: /opt/sea/sg-runner\nConfiguration precedence: Test-specific configuration overrides environment configuration. Environment configuration overrides common configuration. Scenario configuration: Provides default values when no more specific configuration applies. Acts as a fallback mechanism. Scenario templates: Driven by the Jinja2 templating engine. /opt/sea/sg-runner ├── bin/ # Executable tools ├── sbin/ # Main sg-runner scripts ├── etc/ # Common configuration ├── docs/ # Documentation ├── sw/ # Extra tools and software ├── store/ # Test store └── shared/ # Test execution directories Test Store\nstore/ ├── env/ # Environment settings ├── scens/ # Scenario settings │ └── dico/ # Dictionary files └── tests/ # Test setup └── data/ # Test data Test Exeutions directories\nshared/ ├── .run/ # Symlink to the last test execution directory ├── runs/ # Contains all test execution directories ├── tests/ │ └── / # Symlinks to test execution directories by test └── hosts/ └── / # Symlinks to test execution directories by host","test-definition#Test definition":"Main test file: ./test//test.yml Test data: ./test//data/ Parameter Description TestName Must match the test directory name (). TestDesc Human-readable test description. TestEnv Environment configuration name (environment directory). ScenName Scenario name used by the setup script. ScenStore Main configuration source for the scenario. ScenEngine Scenario engine:\n• SG – Seagull\n• JM – JMeter ScenEnv Scenario environment configuration (file name without extension). ScenAttr Attributes applied to the selected scenario. sourceDataFile Path to the source data file (e.g. ./test/data/profile_C.csv)."},"title":"Configuraiton"},"/docs/guide/sg_runner/core_concept/":{"data":{"":"Configuration is composed of environment, test, and scenario settings. A single test may define multiple scenarios, each using tool-specific configuration templates rendered with the Jinja2 engine.\nEach test execution is created in a unique directory containing subdirectories for each scenario. These scenario directories store the generated procedural scripts required for execution.\nThe SG runner supports concurrent execution of multiple scenarios. In Kubernetes environments, it is recommended to execute one scenario per pod.\nHow to Setup Test The system allows users to define tests composed of one or more scenarios. Each scenario represents a specific execution path and is configured independently using predefined templates.\nDuring setup, the system automatically combines environment, test, and scenario settings to generate the required scripts. Each test run is isolated in its own execution directory, ensuring clean separation between runs and scenarios. The setup scripts combine configuration inputs and apply them to tool-specific configurations\nScenarios can be executed in parallel to create well-balanced combinations of test scenarios. When deployed in a Kubernetes environment, each scenario is typically executed in its own pod to provide better isolation, scalability, and resource management.\nKey Benefits\nClear separation between environment, test, and scenario configuration Isolated and reproducible test runs Kubernetes-friendly execution model Template-driven and extensible design Based on the test configuration, procedural scripts are generated in which the appropriate settings are applied.\nIn addition to managing the target tool, the SG Runner is responsible for handling auxiliary processes such as packet capturing (e.g., tcpdump), log analysis, and statistics generation.\nPre-processing scripts are responsible for fetching and preparing test data, while post-processing scripts handle report generation and synchronization with external repositories.\nThe system also includes common procedures for health checks of the SG Runner. These checks verify that all required tools are properly installed, the node is ready to execute scenarios, and sufficient system resources are available (i.e., the node is not resource-constrained or busy).\nTE Directory Structure\nThe test execution script is created under the /opt/sea/sg-runner/shared/runs directory using the naming convention te---.\nIn addition, corresponding symbolic links are created under hosts//last/ and tests//, providing quick access to the most recent test execution for a given host or test name.\nPlease see the section below for details.\nHow Execution Works The execution process begins with setup scripts, followed by the execution of procedural scripts in the defined order. Detailed information for each procedure is provided in the Procedures section.\nThe SG Orchestrator manages individual test executions by following this workflow and continuously monitoring the execution status of each test scenario. If the SG Orchestrator is not used, the same process can be performed manually.\nProcedural scripts and common SG Runner scripts are executable through a REST API interface. For end-to-end testing, the REST API can be integrated with any test automation framework. For performance testing, the use of the SG Orchestrator is strongly recommended.","how-execution-works#How Execution Works":"","how-to-setup--test#How to Setup  Test":""},"title":"Core Concept"},"/docs/guide/sg_runner/getting_started/":{"data":{"":"","installtion#Installtion":"Metal Bear VM Docker Kubernates mkdir -p /opt/sea cd /opt/sea/ git clone https://github.com/atossoftsea/sg-runner.git cd /opt/sea/sg-runner ./sw/install_runner.sh ./sw/install_oems.sh # system test ./sw/test_sit.sh # functinal test ./sw/test_func.sh Access to the runner is provided via SSH on port 22000, using the sg_exec user and an independent SSHD server. The sg_exec user has no privileges to modify test configurations in the ./store directory. For test development purposes, the sg_dev user should be used.\nYou can clone the test store from Git and link it to the ./store directory. The RestAPI service is also available. The server can use a minimal server distribution, with CentOS being the preferred option.\nThis is primarily designed for test scenario development, where the necessary tools are readily available. You can download the SG-Runner_1.0.1.ova image from our repository, then import the .ova file into VirtualBox or VMware.\nThe virtual machine is based on CentOS (with X Windows) and runs SG-Runner_1.0.1. It also includes Wireshark and Visual Studio Code (VSC) on the server.\nYou can clone the test store from Git and link it to the ./store directory. Alternatively, you can copy any scenarios you wish to use into the directory.\nThe sg_exec and sg_dev users are created, with the sg_exec user having privileges limited to executing tests only. The RestAPI service is not available.\ndocker login docker pull sg-runner:0.1.0 docker image sg-runner:0.1.0 # optinally cd # you may clone from sg-test-store or copy scenarios docker image sg-runner:0.1.0 --volume /opt/sea/sg-runner/store: The Docker image is available on DockerHub. It includes its own SSH server, and the sg_exec user is preconfigured and the RestAPI service is also available.\nYou can clone the test store from Git and mount your own test store volume at /opt/sea/sg-runner/store.\ngit clone ... k8s tf terafform \u003c\u003e.tf kubectl cluster init ... helm update / Basically, you set up a farm of SG-Runners on GCP or AWS. The available Helm chart and Terraform configuration are part of the Orchestrator solution."},"title":"Getting Started"},"/docs/guide/sg_runner/overview/":{"data":{"":"Performance and Last test are time and resource consuming. Our tool provides you set of templates and tools to set your tests up. You should be focused on test design and test strategy rather on tools.\nThe Seagull tool basically made for telco industry. And ,it provides comprehensive simulators and reports. Simulator can simulate high Diameter Gy,Sy,Gx,Ro traffic provision traffic as well and SIP traffic.\nJMeter, a leading performance testing tool, supports various interfaces, with emphasis on REST API, SOAP, XML, and HTTP/2.\nSouthbound trafic:\nDiameter: Gy, Sy, Ro, Cx, Gx - for data, voice, and sms services; S6a and S6d mobility managment SIP - voice and sms services HTTP/2 5G SBA Nordbound traffic:\nREST interface XML interface SOAP interface The system is setup and it is explaned under Ecosystem","benefits#Benefits":"Focuses on test strategy execution rather than script-intensive testing Environment-agnostic across MNO and MVNO deployments Supports flexible composition and orchestration of test scenarios Telecom protocols are preconfigured and ready for use Provides extensive coverage with predefined telecom test scenarios Delivers enhanced and detailed test reporting and analytics","features#Features":"Scalable, multi-tool test solution Supports multiple deployment environments, including bare metal, cloud, and Kubernetes Test scenarios compliant with 3GPP standards and 4G/5G network sscenarios Supports Diameter protocols e.g. Gy, Sy, Ro, Sa, Sd and HTTP/2 N28,N40… Supports Nordbound traffic generation using REST APIs, XML, SOAP, and HTTP within test scenarios Simplifies integration with external test tools Provides flexible configuration management for environment-, test-, and scenario-specific parameters Leverages Jinja as a fast, expressive, and extensible templating engine Allows composition of multiple scenarios within a single test Applicable for performance testing as well as end-to-end (E2E) testing Performs health and business-level checks of the test runner engine Supports test data preprocessing, including data generation, blending, and on-the-fly transformation Enables management and real-time monitoring of test execution processes Generates comprehensive reports and statistical insights Captures PCAP traces during test execution Provides real-time log analysis Integrates with a Test Store or custom repositories Exposes a common API interface for integration Supports CLI-based operations over dedicated SSH access Provides a web-based GUI for managing test execution Includes a web-based configuration tool for managing test settings and test data","usefull-links#Usefull Links":"Contributing Seagull documents https://jmeter.apache.org/ Jmeter documents Jinja2 Templates"},"title":"Overview"},"/docs/guide/sg_runner/procedures/":{"data":{"":"","monitoring#Monitoring":"","post-processing#Post-processing":"Setup Set up the test run directory and create test execution scripts according to the configuration.\nPre-processing Fetch test data and process it\nStarting Start the test tool, with the option to run tcpdump or a log analyzer if needed\nMonitoring Check the process status of the tools, dumper, or analyzer\nStoppping Stop the running processes\nPost-processing Post-process the statistical data to generate graphs and statistical reports","post-processing-1#Post Processing":"Post-processing generates statistics and graphs, and compiles them into HTML reports.\n[root@SEA_01 sg_data_normal]# ./post-proc.sh INFO: Test Pre-Proc -------------------------------------------------------- INFO: Test scenario --SEA-OCS-01 --sg_data_normal-- -- 2026-02-10T22:34:42 -- INFO: Scenario Engine=SG INFO: Report index reportIndexTmpl=/opt/sea/sg-runner/run/SEA-OCS-01/web/index.html.j2 reportIndexDir=/opt/sea/sg-runner/run/SEA-OCS-01 INFO: Report reportTmpl=report.html.j2 INFO: Seagull Post-processing statistics -------------------------------------- INFO: Scenario running direcotry /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal INFO: Statistics file stat-global.csv for RTT is processed INFO: Statistics file stat-global.csv for TSP is processed INFO: Statistcs file stat-global.csv for CALL is processed INFO: Statistics graph is generated INFO: Statistics html report is made ------------------------------------------- INFO: Seagull Post-proc --done ------------------------------------------------ INFO: Reporting start ---------------------------------------------------- INFO: Report template reportTemplate=./report.html.j2 INFO: Report Template /opt/sea/sg-runner/ to report.html INFO: Reporting --done ------------------------------------------------ INFO: Reporting Index start ------------------------------------------- INFO: Report Index template reportIndexDir=/opt/sea/sg-runner/run/SEA-OCS-01 reportTemplate=/opt/sea/sg-runner/run/SEA-OCS-01/web/index.html.j2 INFO: Report web directory is setup INFO: Report Template /opt/sea/sg-runner/ to report.html is generated INFO: Reporting Index --done ------------------------------------------ INFO: Test Pre-Proc --done-- ------------------------------------------------- Result\nMore details can be found at Test Result","pre-processing#Pre-processing":"","pre-processing-1#Pre processing":"The pre-processing step collects and organizes the test data. For Diameter or SIP test data, it maintains the data order to prevent clustering of subscriber profiles.\n[root@SEA_01 sg_data_normal]# pwd /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal [root@SEA_01 sg_data_normal]# ./pre-proc.sh INFO: Test Pre-Proc -------------------------------------------------------- INFO: Test scenario --SEA-OCS-01 --sg_data_normal-- -- 2026-02-10T22:29:19 -- INFO: Scenario Engine=SG INFO: Pre-proc mixer start ---------------------------------------------------- INFO: Scenario running directory /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal INFO: Scenario src=data/profile_C.csv ext=msisdn.csv headerLines=2 INFO: Mixer source=/opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal/../data/profile_C.csv ext=/opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal/msisdn.csv Input is loaded Size=998 total 164 drwxr-xr-x. 6 root root 72 Feb 10 22:23 web -rw-r--r--. 1 root root 48169 Feb 10 22:23 sg_dico_cxgysy.xml -rw-r--r--. 1 root root 3928 Feb 10 22:23 sg_data_normal_conf.xml -rw-r--r--. 1 root root 40142 Feb 10 22:23 sg_data_normal_scen.xml -rw-r--r--. 1 root root 5091 Feb 10 22:23 report.html -rwxr-xr-x. 1 root root 588 Feb 10 22:23 pre-proc.sh -rwxr-xr-x. 1 root root 2103 Feb 10 22:23 start.sh -rwxr-xr-x. 1 root root 542 Feb 10 22:23 status.sh -rwxr-xr-x. 1 root root 532 Feb 10 22:23 stop.sh -rwxr-xr-x. 1 root root 803 Feb 10 22:23 post-proc.sh drwxr-xr-x. 2 root root 4096 Feb 10 22:23 bak -rw-r--r--. 1 root root 33967 Feb 10 22:29 msisdn.csv INFO: Mixer no= --done-- INFO: Pre-proc mixer start --done -------------------------------------------- INFO: Test Pre-Proc --DONE-- -------------------------------------------------","see-also#See also":"Contributing Seagull documents Jinja2 Templates","setup#Setup":"","setup-1#Setup":"# login to sg-runner container as sg_dev or sg_exec user cd /opt/sea/sg-runner #setup particlar scenario ./sbin/setup.sh -e \"\" -t \"\" -s \"\" #setup all scenarios ./sbin/setup.sh -e \"\" -t \"\" #setup scenarios mathing them by regex ./sbin/setup.sh -e \"\" -t \"\" -s \"\" Arguments Description test_enviroment Directory that contains the scenario environment file: ./env//.yml test_name The test directory where the data/ folder with test data .csv is populated along with the test.yml file test_scenario It is the ScenName defined in the test.yml configuration, where each scenario points to ./scens//scen.yml Example:\n[root@SEA_01 sg-runner]# ./sbin/setup.sh -e \"Lab01\" -t \"SEA-OCS-01\" -s \"sg_data_normal\" INFO: Test -setup started /opt/sea/sg-runner ----------------------------------------------------------------- INFO: setup run direcotry INFO: new test run direcotry -- /opt/sea/sg-runner/shared/runs/te-SEA-OCS-01-20260210T222329-bb501ca4 -- and links are created INFO: Test=SEA-OCS-01 INFO: Name=SEA-OCS-01 -- INFO: Desc=data,voice,sms and prov xxx INFO: Env=Lab01 TestEnv=Lab01 INFO: Scens=sg_data_normal sg_ims_voice_normal sg_ims_sms_normal mtx_prov_high mtx_prov_test01 sg_ims_sms_test_01 sg_ims_sms_test_02 INFO: Selected Scens=sg_data_normal INFO: Scen=sg_data_normal ------------------------------------------------ INFO: setup current directory is /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal/ INFO: test /opt/sea/sg-runner/store/tests/SEA-OCS-01/ configation and test data applied INFO: Seagull setup - Env=Lab01 Name=SEA-OCS-01 Engine=SG Scen=sg_data_normal scenEnv=sea_pgw Store=sg_data INFO: Seagull setup Att=logLevel: 'WUTE' backgroundExec: 'true' callRate: '50' waitMs: '166667' numberCalls: '770000' maxSimultaneousCalls: '50000' callTimeoutMs: '1000' pcapEnabled: \"false\" externalDataFile: 'msisdn.csv' sourceDataFile: 'data/profile_C.csv' sourceDataConf: 'data/profile_C.yml' noOfccrU: '2' ratingGroup: '2' INFO: enviroment /opt/sea/sg-runner/store/env/Lab01/sea_pgw.yml applied INFO: scenarios test attributes applied INFO: current test run attributes applied INFO: seagull ---------------------------------------------------- INFO: seagull conf temaplate /opt/sea/sg-runner/store/scens/sg_data/sg_conf_c2ip_ADJ.j2 applied INFO: seagull scenario temaplate /opt/sea/sg-runner/store/scens/sg_data/sea_scen_gysy2c_slr_ccrIU_snr_ccrUT_str.j2 applied INFO: seagull dictionary /opt/sea/sg-runner/store/scens/sg_data/sg_dico_cxgysy.xml applied INFO: Report Conf /opt/sea/sg-runner/sbin/web/sg/report_data.yml applied INFO: Report Html Report /opt/sea/sg-runner/sbin/web/sg/report.html.j2 applied INFO: Setup Attr engine=SG test=SEA-OCS-01 scen=sg_data_normal sg_dico=sg_dico_cxgysy.xml sg_conf=sg_data_normal_conf.xml sg_scen=sg_data_normal_scen.xml INFO: setup ------------------------------------------------- INFO: Seagull templates sg_conf=sg_data_normal_conf.xml sg_dico=sg_dico_cxgysy.xml sg_scen=sg_data_normal_scen.xml sg_log=sg_data_normal.log INFO: scenarios setup is merged for Lab01 / sea_pgw.yml testAttr.yml runAttr.yml scen.yml INFO: report ------------------------------------------------- INFO: report setup is merged and /opt/sea/sg-runner/sbin/web/sg/report_data.yml and reportAttr.yml to report.yml INFO: Templating ------------------------------------------------ INFO: SEAGULL INFO: seagull configuration sg_conf_c2ip_ADJ.j2 to sg_data_normal_conf.xml is setup INFO: seagull scenario sea_scen_gysy2c_slr_ccrIU_snr_ccrUT_str.j2 to sg_data_normal_scen.xml is setup INFO: REPORT INFO: Report Template /opt/sea/sg-runner/sbin/web/sg/report.html.j2 to report.html INFO: EXECUTION INFO: Execution pre-proc.sh,start,sh , status.sh, post-proc.sh are created INFO: ------------------------------------------------------------ INFO: Setup Info -------------------------------------------------- INFO: Test Run directory /opt/sea/sg-runner/shared/runs/te-SEA-OCS-01-20260210T222329-bb501ca4 INFO: Test Run Scenario directory /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal/ ... INFO: Test Run data directory /opt/sea/sg-runner/run/SEA-OCS-01/data/ INFO: --data-- total 0 INFO: --data-- lrwxrwxrwx. 1 root root 49 Feb 10 22:23 profile_C.csv -\u003e /opt/sea/sg-runner/store/tests/data/profile_C.csv INFO: Test Runs /opt/sea/sg-runner/shared/runs with 4 runs !!! INFO: Test Runs /opt/sea/sg-runner/shared/runs where disk usage is 2028 Kb INFO: Setup cleanup INFO: Setup cleanup /opt/sea/sg-runner/run tn=SEA-OCS-01 sn=sg_data_normal INFO: Seagull setup - done INFO: Setup done -- - - sg_data_normal -- INFO: Setup result real path is /opt/sea/sg-runner/shared/runs/te-SEA-OCS-01-20260210T222329-bb501ca4 INFO: Result Text object is SETUP_RESULT=FFFF{ \"env\": \"Lab01\", \"test\": \"SEA-OCS-01\", \"scens\": \"sg_data_normal\", \"run_dir\": \"/opt/sea/sg-runner/shared/runs/te-SEA-OCS-01-20260210T222329-bb501ca4\" }FFFF SETUP_RESULT=FFFF{ \"env\": \"Lab01\", \"test\": \"SEA-OCS-01\", \"scens\": \"sg_data_normal\", \"run_dir\": \"/opt/sea/sg-runner/shared/runs/te-SEA-OCS-01-20260210T222329-bb501ca4\" }FFFF INFO: Setup -- DONE -- Test Execution directory\nThere are several ways to locate the test execution directory:\nRun Link: A link to the most recent test execution setup.\n/opt/sea/sg-runner/run → /opt/sea/sg-runner/shared/runs/te---\n/opt/sea/sg-runner/shared/last also points to the same directory\nShared Runs: The main directory is /opt/sea/sg-runner/shared/runs/, where directories in the format te--- are created\nThe test execution directory contains the following files:\n#at te--- direcory └── ├── data │ └── profile_C.csv -\u003e /opt/sea/sg-runner/store/tests/data/profile_C.csv # refering to test data ├── sg_data_normal # scenario directory │ ├── post-proc.sh # generates .png files │ ├── pre-proc.sh # mixing up test data and setting msisdn.csv file │ ├── report.html │ ├── sg_data_normal_conf.xml │ ├── sg_data_normal_scen.xml │ ├── sg_dico_cxgysy.xml │ ├── start.sh # provide logs and output; starting up can take a few minutes │ ├── status.sh # expectation are SEAGULL-OKAY and PCAP-OKAY(if pcap is true ) status │ ├── stop.sh # killing seagull and tcpdump process │ └── web │ ├──... # report html/css files │\t├── sg_voice_ims_normal │\t... ├── sg_sms_ims_normal │ ... │\t└── test.yml","start#Start":"Start the test tool, with optional PCAP capture and Seagull log analysis.\n[root@SEA_01 sg_data_normal]# ./start.sh INFO: Test Start --------------------------------------------------------- INFO: Scenario running directory --/opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal -- INFO: Test scenario started --SEA-OCS-01--sg_data_normal-- INFO: Scenario Engine=SG INFO: Env=Lab01 Test=SEA-OCS-01 Scenario=sg_data_normal INFO: dico=sg_dico_cxgysy.xml conf=sg_data_normal_conf.xml scen=sg_data_normal_scen.xml INFO: log=sg_data_normal.log loglevel=WUTE backgroundExec=true INFO: Pcap pcapEnabled=false inf=any file=sg.%Y%m%dT%H%M%S.pcap rotationPeriod=1800 filter=port 3868 WARN: Pcap pcapEnabled=false is disable INFO: Started seagull in background INFO: Seagull -BG start ---------------------------------------------------- INFO: Scenario running direcotry /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal INFO: Scenario dico=sg_dico_cxgysy.xml conf=sg_data_normal_conf.xml scen=sg_data_normal_scen.xml log=sg_data_normal.log llevel=WUTE INFO: export PATH=$PATH:/opt/sea/sg-runner/bin INFO: export LD_LIBRARY_PATH=/usr/local/bin:/opt/sea/sg-runner/lib INFO: seagull -conf /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal/sg_data_normal_conf.xml -dico /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal/sg_dico_cxgysy.xml -scen /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal/sg_data_normal_scen.xml -log /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal/sg_data_normal.log -llevel WUTE -bg Background mode - PID [978565] INFO: --seagull status -- root 978574 978305 0 22:30 pts/0 00:00:00 grep 978565 INFO: Seagull -BG started Pid=978565 pidOf=978565 ExitCode=0 --SEAGULL-START-- cat: ./tcpdump.pid: No such file or directory INFO: Test Start -- seagull-pid-file=978565 -- pcap-pid-file= INFO: Seagull start --done -------------------------------------------------- INFO: Test scenario started --SEA-OCS-01 --sg_data_normal-- --2026-02-10T22:30:42-- cat: ./tcpdump.pid: No such file or directory INFO: Test Start -- seagull-pid-file=978565 -- pcap-pid-file= INFO: Test Start -- Done -- --------------------------------------------","starting#Starting":"","status#Status":"Provides the status of the running test tool and any optional processes.\n[root@SEA_01 sg_data_normal]# ./status.sh INFO: Test Status -------------------------------------------------------- INFO: Test scenario --SEA-OCS-01 --sg_data_normal-- -- 2026-02-10T22:32:53 -- INFO: Scenario Engine=SG INFO: Pcap status -------------------------------------------------- INFO: Scenario running direcotry /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal WARN: Pcap pid file does not exists INFO: Pcap status --done ---------------------------------------------- INFO: Seagull status -------------------------------------------------- INFO: Scenario running direcotry /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal INFO: --any seagull pid=978565 status -- root 978565 1 99 22:30 pts/0 00:02:10 seagull -conf /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal/sg_data_normal_conf.xml -dico /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal/sg_dico_cxgysy.xml -scen /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal/sg_data_normal_scen.xml -log /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal/sg_data_normal.log -llevel WUTE -bg DEBUG: Seagull seagullPsAcc=1 , process for pid=978565 INFO: Seagull pid=978565, processes is running --SEAGULL-OK-- INFO: Seagull status --done ------------------------------------------------ cat: ./tcpdump.pid: No such file or directory INFO: Test Status seagull-pid-file=978565 -- pcap pid-file= INFO: Test Status --DONE-- ------------------------------------------------- [root@SEA_01 sg_data_normal]#","stop#Stop":"Stops the test tool (Seagull or JMeter) along with all optionally started processes.\n[root@SEA_01 sg_data_normal]# ./stop.sh INFO: Test Stop -------------------------------------------------------- INFO: Test scenario --SEA-OCS-01 --sg_data_normal-- -- 2026-02-10T22:33:53 -- INFO: Scenario Engine=SG INFO: Pcap stop ------------------------------------------------------- INFO: Scenario running direcotry /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal INFO: --any tcpdump status -- root 980584 980553 0 22:33 pts/0 00:00:00 xargs -I{} echo INFO: --any tcpdump status -- {} WARN: Pcap pid file does not exists INFO: Pcap stop --done ------------------------------------------------ INFO: Seagull stop ---------------------------------------------------- INFO: Scenario running direcotry /opt/sea/sg-runner/run/SEA-OCS-01/sg_data_normal INFO: Seagull pid=978565 is killed --SEAGULL-STOP-- INFO: Seagull stop --done -------------------------------------------------- cat: ./tcpdump.pid: No such file or directory INFO: Test Stop seagull-pid-file=978565 -- pcap pid-file= INFO: Test Stop --DONE-- ------------------------------------------------- [root@SEA_01 sg_data_normal]#","stoppping#Stoppping":""},"title":"Procedures"},"/docs/guide/sg_runner/reports/":{"data":{"":"","diamater-traffic----symultenius-sessions#Diamater Traffic -  Symultenius Sessions":"Note: Maintains a smooth number of simultaneous sessions","diamater-traffic---round-trip-time#Diamater Traffic - Round Trip time":"Note: Maintains the target TPS level, though spikes may occur due to the nature of the scenario. These spikes are more noticeable because of the behavior of the system under test.","diamater-traffic---transaction-per-scounds#Diamater Traffic - Transaction per scounds":"Note: Maintains the target TPS level, although occasional spikes may occur due to the nature of the scenario. CCR messages can overlap within very short time periods. By recalculating wait-ms/call rates numerically, results can be improved. As a side effect, the TPS level may deviate by less than 0.9%."},"title":"Test Reports"},"/docs/guide/sg_runner/roadmap/":{"data":{"":"","community#Community":"","sg-runner-realse-note#SG Runner: Realse Note":"Features Description 0.1.0 0.1.2 healty helatiness,readiness and bissiness audult x x setup seagull seagull tool integration x x setup jmeter jmeter tool integration x x procedures classic prcedures x x reports html, statiscs, graphs x x logs analyser online log analysing, generates report x trigger log online parsing and trigger rest store basic client/server scnearios diameter,sip,http x e2e attrs E2E test, no iteration x OTEL Grafana dash bord sof running tests Docs x x"},"title":"Roadmap"},"/docs/guide/sg_runner/test_dev/":{"data":{"":"Devloper Only","setup-pcap-capturing#Setup pcap capturing":"For Linux desktop:\nFor Linux desktop: mkfifo /tmp/tmp.pcap ssh -P 22 root@192.168.220.135 “tcpdump -s 0 -U -n -w - -i lo not port 3686” \u003e /tmp/tmp.pcap Launch Wireshark and capture traffic from the FIFO file /tmp/tmp.pcap.\nFor Win desktop:\nssh -P 22 root@192.168.220.135 “tcpdump -s 0 -U -n -w - -i lo not port 3686” \u003e tmp.pcap Launch Wireshark and capture data from the FIFO file /tmp/tmp.pcap.","setup-test-user#Setup test user":"Use the FTP user on SG-Runner Use Notepad++ with plugins like NppXMLTree, NppFTP, or Visual Studio Code Add a test developer user exclusively for SFTP access vi /etc/sshd/sshd_config #SFTP Match User sea_dev ChrootDirectory /opt/sea/ ForceCommand internal-sftp"},"title":"Hints \u0026\u0026 Ticks"},"/docs/guide/sg_runner/test_tools/":{"data":{"":"SG-Runner is a modular framework designed to integrate with a wide range of tools. Using Jinja2 templates, provids dynamic and configurable tool definitions. Templates allow users to parameterize commands, configuration files, and workflows using variables, conditionals, and reusable components. SG-Runner Tools is capable of transforming reports into graphical representations and generating statistical analysis results.\nSupported test tools:\nSeagull: Multi-protocol 4G/5G traffic symulator Jmeter: SOAP/XML/REST Webservices traffic generator","jmeter#JMeter":"Apache JMeter may be used to test performance both on static and dynamic resources, Web dynamic applications. It can be used to simulate a heavy load on a server, group of servers, network or object to test its strength or to analyze overall performance under different load types.\nJMeter Features:\nApache JMeter features include:\nAbility to load and performance test many different applications/server/protocol types: Web - HTTP, HTTPS (Java, NodeJS, PHP, ASP.NET, …) SOAP / REST Webservices FTP Database via JDBC LDAP Message-oriented middleware (MOM) via JMS Mail - SMTP(S), POP3(S) and IMAP(S) Native commands or shell scripts TCP Java Objects Full featured Test IDE that allows fast Test Plan recording (from Browsers or native applications), building and debugging. CLI mode (Command-line mode (previously called Non GUI) / headless mode) to load test from any Java compatible OS (Linux, Windows, Mac OSX, …) A complete and ready to present dynamic HTML report Easy correlation through ability to extract data from most popular response formats, HTML, JSON , XML or any textual format Complete portability and 100% Java purity. Full multi-threading framework allows concurrent sampling by many threads and simultaneous sampling of different functions by separate thread groups. Caching and offline analysis/replaying of test results. Highly Extensible core: Pluggable Samplers allow unlimited testing capabilities. Scriptable Samplers (JSR223-compatible languages like Groovy and BeanShell) Several load statistics may be chosen with pluggable timers. Data analysis and visualization plugins allow great extensibility as well as personalization. Functions can be used to provide dynamic input to a test or provide data manipulation. Easy Continuous Integration through 3rd party Open Source libraries for Maven, Gradle and Jenkins.","seagull-tool#Seagull Tool":"Seagull is a free, Open Source (GPL) multi-protocol traffic generator test tool. Primarily aimed at IMS (3GPP, TISPAN, CableLabs) protocols (and thus being the perfect complement to SIPp for IMS testing), Seagull is a powerful traffic generator for functional, load, endurance, stress and performance/benchmark tests for almost any kind of protocol.\nSeagull Features:\nSeagull has the following features:\nMulti-protocol traffic generator Command line tool with text interface Protocols of the same family are described in an XML, user editable, dictionary (messages, parameters) Existing protocol families: Binary/TLV (Type, Length, Value), Raw binary, Text, external API (first implementation: HP OpenCall SS7) Support of IP (UDP/TCP), SCTP, SSL/TLS and SS7/TCAP transports Portable programming (tested and supported on Linux x86, ia64, HPUX, SunOS and Windows) Scenarios are described using XML files Multi-threaded for performances and reliability Dynamically adjustable scenario rate Uniform, Poisson or Best-effort scenario arrival distribution Remote-control (scenario-rate set, counter dump) through standard HTTP interface Pause and restart of traffic Support of automated traffic profile (varying scenario rate) Smooth (no new scenarios then wait for ongoing scenarios to end) or brutal end Scenario display with message counters Scenarios have init (executed once), main (repeated for traffic) sections Scenarios have default sections for defense in case of unexpected messages A scenario can be mono (most cases) or multi-protocol Message and parameters checking possible (disabled by default) Support of parameter injection following a CSV like database Multiple Seagull instances can be synchronized in the middle of scenario Intra scenario synchronization using a synchronization protocol (example application provided in Java language) Statistics: timer between two messages, scenario length, scenario rate, successful scenarios, failed scenarios (with reason) Protocol decoding and hexadecimal dump Trace files with or without timestamps (for performances and automation)","usefull-links#Usefull Links":"Contributing Seagull documents https://jmeter.apache.org/ Jmeter documents Jinja2 Templates"},"title":"Test Tools"},"/docs/guide/sg_runner/web_gui/":{"data":{"":"","web-ui-config-test-configuration#Web-UI-Config: Test Configuration":"Feature\nOversees system health Controls test procedures Offers flexible form configurations Supports all YAML configurations Provides default configuration options Enables basic authentication","web-ui-exec--test-execution#Web-UI-Exec:  Test Execution":"Feature\nManage and monitors health, readiness, and business statuses Manages execution across all phases: setup, pre-processing, start, status monitoring, stop, and post-processing Supports downloading of reports, logs, and PCAP files Captures live logs during test execution"},"title":"Web UI"},"/eco/cloud/":{"data":{"":"","cloud-native#Cloud Native":"","sg-commander#SG-Commander":"on the roadmap","sg-runner#SG-Runner":"The solution is based on VMs in the archive SG-runner-0.1.0.ova The Sg-Runner should have connectivity TCP or SCTP to the Diameter Server under test. The acces to the runner by ssh connection over port 22000 as user sg_exec. The sg_exec user does not have privilages to change test configuration at ./store direcotry.\nIn the case of test devlopment use sg_dev shell be used.\nThere is possibilites to download our image VM file from our repository. The VM is given in SG-Runner_1.0.1.ova file"},"title":"Cloud Native"},"/eco/container/":{"data":{"":"","container-native#Container Native":"","docker#Docker":"Lern how to install The Docker\nTry ru run docker host or on VM and setup docker up and pull image.\n[root@sg_run_01 docs]# docker pull atossoftsea/sg-runner:1.0.1 1.0.1: Pulling from atossoftsea/sg-runner Digest: sha256:65a726a8e13cfa960b10859ae97e6d0e23a98c4bf0ab831cbb4bb72ca418e85a Status: Image is up to date for atossoftsea/sg-runner:1.0.1 docker.io/atossoftsea/sg-runner:1.0.1 [root@sg_run_01 docs]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE atossoftsea/sg-runner 1.0.1 135a1acdc473 2 hours ago 770MB The access to docker by ssh are avaible using private key.\nStart containe and login by ssh sg@172.17.0.2 -p 20022 -i ../ssh_host_rsa_key in case if ssh is not avaible still you can access by running docker run -it …","how-to-start#How to start":"By docker run expected outpotus is given rhen start docker image. After you may run tests\n[root@sg_run_01 docs]# docker run atossoftsea/sg-runner:1.0.1 ... INFO: Enty-point is reached INFO: Entry-point - ./10-openssh-server.sh is starting INFO: Open SSH-Server WARN: There are more then one ip address INFO: Assigned ADDR=172.17.0.2 INFO Server pid={} exit_code=0 INFO: Entry-point - ./99-sg-engine-status.sh is starting INFO: Sg-Engin - status -start INFO: Sg-Engine - status pooling if no ssh aviable\n[root@sg_run_01 docs]# docker run -it atossoftsea/sg-runner:1.0.1 bash --RUN-- ... [root@2f614beff882 /]# # E.g. after you may run tests as following into container [root@2f614beff882 /]cd /opt/sea/sg-runner/ ./sbin/setup.sh -e \"Lab01\" -t \"SEA01\" -s \"sg_data_normal\" INFO ... ... [root@2f614beff882 /]cd ./run/SEA01/sg_data_normal/ [root@2f614beff882 /] ls -l *.sh ./pre-proc.sh ./start.sh ./status.sh ./stop.sh ./post-proc.sh Integrate it with Test-Store\nAll test configuration are place at sg-test-store, results at shared direcotres\n[root@sg_run_01 docs]# mkdir -p [root@sg_run_01 docs]# cd [root@sg_run_01 docs]# mkdir shared [root@sg_run_01 docs]# git clone https://github.com/atossoftsea/sg-test-store.git [root@sg_run_01 docs]# docker run -it \\ -v ${pwd}/sg-test-store/:/opt/sea/sg-runner/store/ \\ -v $(pwd)/shared/:/opt/sea/sg-runner/shared \\ atossoftsea/sg-runner:1.0.1","kubernetes-native#Kubernetes native":"The kubernetes is modern, scalable solution, provides varates to extend to unlimted traffic load.\nNote\nThe terafform scripts shell be provided to manage infrastructures The helmchart scripts shell scale up/down K8S costs","sg-commander#SG-Commander":"on the roadmap","sg-runner#SG-Runner":"The solution is on DockerHub as image sg-runner:1.0.1.\nThe acces to the runner by ssh connection over port 22000 as user sg_exec or sg_dev user. The sg_exec user have privilages to execute test where sg_dev has prilivilages to execute and to change test configuration at ./store direcotry.\nIn the case of test devlopment use sg_dev shell be used.\nThe solution are able to deploy in Kuberanetes cluster.\nThe deployment at GKE enviroment has accepted already."},"title":"Container Native"},"/eco/getting_started/":{"data":{"":"","getting-started#Getting Started":"A vendor-neutral orchestration framework for automated, large-scale performance testing of telecom network functions and cloud-native telco workloads","try-on-docker#Try on Docker":"Learn how to use docker SG Runner image is avaiable on our DockerHub atossoftsea/sg-runner:1.0.1 . Try run docker host or on VM and setup docker up and pull image.\nThere is possibility run SG-Runner as single or more images. As Devloper, it is recommeded to use SG-Runner as single and mount your test repository at /opt/sea/sg-runner/store.\nAll information you may catch on guidles given\nNote: if you use docker to use seagull in server mode be aware to publish configured port e.g 3868 for diameter","try-on-kubernates#Try on kubernates":"Learn how to use minikube , the easiest way to use Falco on Kubernetes in a local environment is on Minikube.\nWhen running minikube with one of the following drivers virtualbox, qemu, kvm2, it creates a VM that runs the various Kubernetes services and a container framework to run Pods, etc. Generally, it’s not possible to build SG-Runner or SG-Orchestration on the minikube VM, as the VM doesn’t include the kernel headers for the running kernel.\nTo address this, starting SG-Runner or SG-Orchestration last 2 minikube major versions, including minor versions, are available at Minikube.\nYou can follow the official guide to install on container.\nNote: Ensure that you have installed kubectl and k9s","try-on-vm#Try on VM":"The solution is based on VMs in the archive SG-runner-0.1.0.ova\nThe sg_exec user does not have privilages to change test configuration at ./store direcotry. In the case of test devlopment use sg_dev shell be used.\nEnsure that virtualbox, kvm or vmware is already installed."},"title":"Getting Started"},"/eco/metal_bear/":{"data":{"":"","installtion#Installtion":"mkdir -p /opt/sea cd /opt/sea/ git clone https://github.com/atossoftsea/sg-runner.git cd /opt/sea/sg-runner ./sw/install_runner.sh ./sw/install_oems.sh","meatal-bear#Meatal Bear":"","sg-commander#SG-Commander":"on the roadmap","sg-runner#SG-Runner":"The software , installtion procedure and system test script are provided for follwings:\nSG-runner-0.1.0 The Sg-Runner should have connectivity TCP or SCTP to the Diameter Server under test.\nThe acces to the runner by ssh connection over port 22000 as user sg_exec. The sg_exec user does not have privilages to change test configuration at ./store direcotry. In the case of test devlopment use sg_dev shell be used.","test-and-verify#Test and verify":"There is possibility to executes test system or functinal test. The system will check installed OEMs tools needed for SG-Runner.\nWhere functinal test will check SG-Runner procedures. Please sea link Procedures\n# system test ./sw/test_sit.sh # functinal test ./sw/test_func.sh"},"title":"Metal Bear"}}